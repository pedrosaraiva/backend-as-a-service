---
layout: post
title: 'Doing the Twitter API Integration Math'
url: http://apivoice.com/2012/06/05/doing-the-twitter-api-integration-math/
image: http://kinlane-productions.s3.amazonaws.com/api-evangelist-site/blog/twitter-full-logo-black.png
---

<p>I’m expanding the API Evangelist network. I’ve recently taken down the API area of API Evangelist, and launching under the brand API stack.  Then I’m formalizing some aspects of my API industry monitoring in two areas: API Ranking - I’ve developed a decent algorithm for ranking APIs, and I want to do it regularly, in real-time API Monitoring - Real-time monitoring and analysis of APIs their blogs, twitter accounts and Internet sentiment about APIs One aspect of this work is using Twitter to monitor and rank the API landscape with the following data points: APIs Twitter Accounts - Pull all the tweets in real-time for 900+ APIs I’m watching API @Mentions - Pull all the @mentions for APIs in real-time for the 900+ APIs I’m watching Industry Keyword Industry Monitoring - Monitor 80+ keywords I’m watching, pulling tweets searches for these Service Providers - Pull all the Tweets for an average of 5 Twitter accounts for each of 20 service providers, @mentions for those account plus keyword searches for their business name Hackathons - Pull Tweets for about an average of 50 hackathons per month, plus the #hashtags for each of those events as well In short, I need to pull quite a few Tweets from quite a few different Twitter API searches and Twitter user accounts. The velocity (number of tweets sent) for each of these data points can vary. As some APIs are only Tweeting once or twice a week, while some are well....the Twitter API account with quite a few tweets as well as numerous @mentions. It’s really impossible to know what volume I’m going to be pulling each hour, but I guess I’m going to figure out pretty quickly. To begin pulling Tweets, I acknowledge I have three optons: Twitter REST API - Pull directly from the public Twitter REST API Twitter Streaming API - Pull using the public Twitter Streaming API Twitter Resellers (Gnip and Datasift) - Approach each of the two partners and understand the scope and costs involved First let’s talk about pros and cons of each source for Twitter data: Twitter REST API - Pro: Free access, I’m also allowed to re-display the Tweets. Con: 150 unauthenticated / 350 authenticated requests per hour per IP address Twitter Streaming API - Pros: Tweets come in real-time. Cons: “All accounts may access the statuses/sample and statuses/filter methods at default access levels. Accounts may also be granted broader data access on these same methods on a case-by-case basis. Access to other methods requires a special arrangement with Twitter. Contact Contact Twitter with your use case, a brief description of your organization, and the requested access level(s).” OK not sure what that means?? And bonus, it never exceeds 1% of fulll Twitter firehose. Twitter Resellers - Pros: Potentially access 50% of full firehose, and more reliable access  Cons: Costs a lot of $$ + .10 per 1000 tweets for licensing through them, and can’t redisplay any Tweets I talked about the self-service vs. sales oriented approaches of Datasift vs. Gnip the other day, so I’m still figuring out scope and costs here. With Gnip its the hurry up and wait enterprise sales approach and with Datasift I have to figure out how to setup the proper streams, and how much work I can get done for one of their DPU (Data Processing Unit). 50% of my Twitter usage will be analytical vs other 50% be display, meaning I will be making ranking and monitoring decisions programmatically rom the Twitter data, but I would also like to show Tweets on the detail pages for APIs, Hackathons and Service providers. I do this currently for Hackathons, but APIs and Service Providers it will be a new thing. So immediately I’m faced with a business decision. The only way I can get Tweets if I want to display is via Twitter public API--if I get through Gnip or Datasift I can’t display them. I’m left with using Twitter REST API or Streaming API to get what I need. Now my concern is rate limits. I am doing a lot of predictive math to understand what my Twitter API consumption will be, to understand what my plan of attack will be. I will have to use multiple machines to scale this as to expand my public facing IP exposure to Twitter--this will be costly. I’m exploring using Iron.io as a possible solution for handling my jobs. Since I really want to be able to display Tweets, I will be starting with the Twitter API. But I will also figure out scope and costs for Gnip and Datasift simultaneously. But this process has really taken the joy out of my project. I would much rather be hacking a way, building my monitoring and ranking system, then either via my own dashboard or something Twitter should be providing, understand my API consumption. Then I’d be very happy to pay for that usage to save me the headache and time I’m going through.  Ok, back to reality.   Now that I’ve done my basic Twitter API integration math, now for a little more work on hacking together the solution to pull from Twitter public API, crank it up to high gear and see where I start hitting the API rate limits--and since there is no relief valve from Twitter for API rate limiting, I will have to create my own relief valve or make other decisions, like having to use Gnip or Datasift.</p>
<center><p><a href="http://apivoice.com/2012/06/05/doing-the-twitter-api-integration-math/" style='padding:25px; font-sze:18px; font-weight: bold;'>Read Full Story</a></p></center>
